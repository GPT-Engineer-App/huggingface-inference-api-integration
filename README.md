# huggingface-inference-api-integration

A Python code snippet for integrating with the Hugging Face Inference API, specifically using the NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO model. The code includes the import statement for the HuggingFaceInferenceAPI class, the setting of the model and token variables, and the instantiation of the HuggingFaceInferenceAPI class with the specified model, token, and max_new_tokens parameter. It demonstrates how to set up the environment variable for the Hugging Face token and how to initialize the language model for making inference requests.

## Collaborate with GPT Engineer

This is a [gptengineer.app](https://gptengineer.app)-synced repository ðŸŒŸðŸ¤–

Changes made via gptengineer.app will be committed to this repo.

If you clone this repo and push changes, you will have them reflected in the GPT Engineer UI.

## Setup

```sh
git clone https://github.com/GPT-Engineer-App/huggingface-inference-api-integration.git
cd huggingface-inference-api-integration
npm i
```

```sh
npm run dev
```

This will run a dev server with auto reloading and an instant preview.

## Tech stack

- [Vite](https://vitejs.dev/)
- [React](https://react.dev/)
- [Chakra UI](https://chakra-ui.com/)

## Requirements

- Node.js & npm - [install with nvm](https://github.com/nvm-sh/nvm#installing-and-updating)
